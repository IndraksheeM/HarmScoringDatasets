{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import undetected_chromedriver as uc\n",
    "import time\n",
    "import json\n",
    "from tqdm import tqdm  # Progress bar\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException, NoSuchElementException\n",
    "import pandas as pd \n",
    "import os\n",
    "from bs4 import BeautifulSoup\n",
    "import utils\n",
    "import hashlib\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import random\n",
    "from selenium import webdriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = uc.Chrome(headless=False, use_subprocess=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.login(driver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: read the profile details\n",
    "with open(\"profiles.json\", \"r\", encoding=\"utf-8\") as file:\n",
    "    profiles = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://www.instagram.com/p/DBNDq3YRW7S/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import hashlib\n",
    "import json\n",
    "\n",
    "def load_comments():\n",
    "    comments_section = driver.find_element(By.XPATH, '/html/body/div[1]/div/div/div[2]/div/div/div[1]/div[1]/div[1]/section/main/div/div[1]/div/div[2]/div/div[2]')\n",
    "\n",
    "    while True:\n",
    "        driver.execute_script(\"arguments[0].scrollTop = arguments[0].scrollHeight\", comments_section)\n",
    "        time.sleep(4)  \n",
    "\n",
    "        try:\n",
    "            load_more_button = driver.find_element(By.XPATH, \"//button[contains(text(), 'Load more comments')]\")\n",
    "            driver.execute_script(\"arguments[0].click();\", load_more_button)  \n",
    "            #print(\"Clicked 'Load more comments' button\")\n",
    "            time.sleep(5)  \n",
    "        except NoSuchElementException:\n",
    "            prev_height = driver.execute_script(\"return arguments[0].scrollHeight\", comments_section)\n",
    "            driver.execute_script(\"arguments[0].scrollTop = arguments[0].scrollHeight\", comments_section)\n",
    "            time.sleep(5)\n",
    "            new_height = driver.execute_script(\"return arguments[0].scrollHeight\", comments_section)\n",
    "\n",
    "            if prev_height == new_height:  \n",
    "                #print(\"Reached the end of comments.\")\n",
    "                break\n",
    "\n",
    "def extract_comment(comment, hidden=False):\n",
    "    try:\n",
    "        # 1. Extract Username\n",
    "        username_tag = comment.find(\"a\", href=True)\n",
    "        username = username_tag['href'].strip().replace(\"/\", \"\") if username_tag else None\n",
    "\n",
    "        # 2. Extract Profile Thumbnail (User Profile Picture)\n",
    "        profile_img_tag = username_tag.find(\"img\") if username_tag else None\n",
    "        profile_thumbnail = profile_img_tag[\"src\"] if profile_img_tag else None\n",
    "\n",
    "        # 3. Extract Comment Text (Avoid timestamps, likes, and username)\n",
    "        comment_text = None\n",
    "        all_spans = comment.find_all(\"span\", dir=\"auto\")  # Look for spans with actual comment text\n",
    "        for span in all_spans:\n",
    "            span_text = span.get_text(strip=True)\n",
    "            if span_text and username not in span_text and not span_text.endswith((\"w\", \"d\", \"h\", \"m\", \"s\")):\n",
    "                comment_text = span_text  # Ensure it's not the timestamp\n",
    "                break  # Get only the first valid comment text\n",
    "\n",
    "        # 4. Extract Comment Image or GIF (Only images inside the comment, not profile picture)\n",
    "        comment_image = None\n",
    "        for img_tag in comment.find_all(\"img\"):\n",
    "            img_src = img_tag[\"src\"]\n",
    "            # Ensure the image is not the profile picture\n",
    "            if profile_thumbnail and img_src != profile_thumbnail:\n",
    "                comment_image = img_src\n",
    "                break  # Only take the first relevant image in the comment\n",
    "\n",
    "        # 5. Extract Likes\n",
    "        num_likes = None\n",
    "        for span in all_spans:\n",
    "            text = span.get_text(separator=' ')\n",
    "            if text.endswith('likes'):\n",
    "                try:\n",
    "                    num_likes = int(text.split(\" \")[0])  # Extract first number\n",
    "                except ValueError:\n",
    "                    num_likes = None\n",
    "\n",
    "        # 6. Extract Replies (Fixing this part)\n",
    "        num_replies = None\n",
    "        for span in all_spans:\n",
    "            text = span.get_text(strip=True)\n",
    "            if \"replies\" in text and \"View all\" in text:\n",
    "                match = re.search(r\"View all (\\d+) replies\", text)\n",
    "                if match:\n",
    "                    num_replies = int(match.group(1))\n",
    "            elif text.startswith(\"View \") and text.endswith(\" replies\"):  # Handle cases like \"View 2 replies\"\n",
    "                match = re.search(r\"View (\\d+) replies\", text)\n",
    "                if match:\n",
    "                    num_replies = int(match.group(1))\n",
    "\n",
    "        # 7. Extract Timestamp\n",
    "        time_tag = comment.find(\"time\")\n",
    "        commented_time = time_tag.text.strip() if time_tag else None\n",
    "\n",
    "        # 8. Generate Unique Comment ID\n",
    "        comment_id_source = f\"{username}-{commented_time}-{comment_text}\"\n",
    "        comment_id = hashlib.md5(comment_id_source.encode()).hexdigest() if comment_text else None\n",
    "\n",
    "        return {\n",
    "            \"username\": username,\n",
    "            \"profile_thumbnail\": profile_thumbnail,\n",
    "            \"comment\": comment_text,\n",
    "            \"comment_image\": comment_image,\n",
    "            \"likes\": num_likes,\n",
    "            \"replies\": num_replies,\n",
    "            \"time\": commented_time,\n",
    "            \"comment_id\": comment_id,\n",
    "            \"hidden\": hidden\n",
    "        }\n",
    "    except Exception as e:\n",
    "        #print(f\"Error extracting comment: {e}\")\n",
    "        return None\n",
    "\n",
    "    \n",
    "def get_comments(comment_objects, hidden=False):\n",
    "    extracted_comments = [extract_comment(comment, hidden=hidden) for comment in comment_objects if extract_comment(comment, hidden=hidden)]\n",
    "    return extracted_comments\n",
    "\n",
    "def get_all_comments():\n",
    "    # First, load or scroll to ensure comments are present\n",
    "    load_comments()\n",
    "    \n",
    "    # Try to reveal hidden comments\n",
    "    try:\n",
    "        hidden_button = driver.find_element(By.XPATH, \"//span[contains(text(), 'View hidden comments')]\")\n",
    "        hidden_button.click()\n",
    "        time.sleep(2)  # or use explicit wait\n",
    "    except NoSuchElementException:\n",
    "        pass\n",
    "    \n",
    "    # Parse out everything\n",
    "    load_comments()  # make sure everything is fully loaded or scrolled\n",
    "    hidden_comments_data = []\n",
    "    found_hidden_div = False\n",
    "    \n",
    "    try:\n",
    "        # If there's a \"Hidden by Instagram\" indicator, stash it\n",
    "        driver.find_element(By.XPATH, \"//span[contains(text(), 'Hidden by Instagram')]\")\n",
    "        hidden_by_instagram_exists = True\n",
    "    except NoSuchElementException:\n",
    "        hidden_by_instagram_exists = False\n",
    "    \n",
    "    # Get the container for all comments\n",
    "    reply_button = driver.find_element(By.XPATH, \"//span[contains(text(), 'Reply')]\")\n",
    "    comments_container = reply_button.find_element(By.XPATH, './ancestor::*[9]')  # Adjust if needed    \n",
    "    all_comments = comments_container.find_elements(By.XPATH, \"./div\")\n",
    "    \n",
    "    for comment in all_comments:\n",
    "        comment_text = comment.text.strip()\n",
    "        # Detect the \"Hidden by Instagram\" marker.  If it appears, flip the flag\n",
    "        if \"Hidden by Instagram\" in comment_text:\n",
    "            found_hidden_div = True\n",
    "            continue\n",
    "        \n",
    "        # Actually parse the comment\n",
    "        hidden_comments_data.append(\n",
    "            extract_comment(\n",
    "                BeautifulSoup(comment.get_attribute(\"outerHTML\"), \"html.parser\"),\n",
    "                hidden=found_hidden_div\n",
    "            )\n",
    "        )\n",
    "    \n",
    "    return hidden_comments_data\n",
    "\n",
    "\n",
    "def save_comments(postId, comments):\n",
    "    filename = f\"comments/{postId}_comments.json\"\n",
    "    with open(filename, 'w', encoding='utf-8') as file:\n",
    "        json.dump(comments, file, indent=4, ensure_ascii=False)\n",
    "    print(f\"Comments saved to {filename}\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_post_metadata(postId):\n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    for i in soup.find_all(\"a\"):\n",
    "        if \"liked_by\" in i['href']:\n",
    "            likes = i.getText().replace(\" likes\", \"\").replace(\",\", \"\")\n",
    "            break\n",
    "    postTime = soup.find(\"time\")['datetime']\n",
    "    with open('post_metadata.csv', 'a') as f:\n",
    "        f.writelines(f\"{postId},{likes},{postTime}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://www.instagram.com/p/DBNDq3YRW7S/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36/36 [00:00<00:00, 2988.28it/s]\n",
      "100%|██████████| 33/33 [00:00<00:00, 2504.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scraped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:00<00:00, 1957.21it/s]\n",
      "100%|██████████| 29/29 [00:00<00:00, 3478.96it/s]\n",
      "100%|██████████| 41/41 [00:00<00:00, 1190.72it/s]\n",
      "100%|██████████| 44/44 [00:00<00:00, 3662.06it/s]\n",
      "100%|██████████| 35/35 [00:00<00:00, 3340.02it/s]\n",
      "100%|██████████| 32/32 [00:00<00:00, 3612.08it/s]\n",
      "100%|██████████| 38/38 [00:00<00:00, 3627.71it/s]\n",
      "100%|██████████| 43/43 [00:00<00:00, 3779.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scraped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 44/44 [00:00<00:00, 3626.44it/s]\n",
      "100%|██████████| 31/31 [00:00<00:00, 3620.51it/s]\n",
      "100%|██████████| 44/44 [00:00<00:00, 3523.68it/s]\n",
      " 52%|█████▏    | 13/25 [00:00<00:00, 66.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 45/45 [00:00<00:00, 3806.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scraped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 43/43 [00:00<00:00, 3213.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 42/42 [00:00<00:00, 1039.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 45/45 [00:00<00:00, 2683.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 45/45 [00:00<00:00, 3331.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:00<00:00, 2850.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 44/44 [00:00<00:00, 3425.13it/s]\n",
      " 80%|████████  | 20/25 [00:00<00:00, 58.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 43/43 [00:00<00:00, 3582.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 42/42 [00:00<00:00, 1843.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 44/44 [00:00<00:00, 3356.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 45/45 [00:00<00:00, 3337.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 43/43 [00:00<00:00, 2880.84it/s]\n",
      "100%|██████████| 25/25 [00:00<00:00, 58.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n",
      "scraped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for profile in tqdm(profiles):\n",
    "    for post in tqdm(profile[\"posts\"]):\n",
    "        post = '/'.join(post.split(\"/\")[2:])\n",
    "        if post.split(\"/\")[-2] not in [i.replace(\"_comments.json\", \"\") for i in os.listdir(\"comments\")]:\n",
    "            print(\"scraped\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "scraped = [i.replace(\"_comments.json\", \"\") for i in os.listdir(\"comments\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "posts = []\n",
    "\n",
    "for profile in profiles:\n",
    "    for post in profile[\"posts\"]:\n",
    "        if post.split(\"/\")[-2] not in scraped:\n",
    "            posts.append(post)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(posts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.instagram.com/adityamadiraju/reel/DFLpKTPv1L-/\n",
      "\n",
      "https://www.instagram.com/adityamadiraju/reel/DFLM-6KOs3u/\n",
      "\n",
      "https://www.instagram.com/adityamadiraju/reel/DFK094auhht/\n",
      "\n",
      "https://www.instagram.com/adityamadiraju/reel/DFIoZPduidP/\n",
      "\n",
      "https://www.instagram.com/adityamadiraju/reel/DFIg09Lu91i/\n",
      "\n",
      "https://www.instagram.com/adityamadiraju/reel/DFHR1YeONaG/\n",
      "\n",
      "https://www.instagram.com/adityamadiraju/reel/DFGJGwgOaE-/\n",
      "\n",
      "https://www.instagram.com/adityamadiraju/p/DFAlpCeuytZ/\n",
      "\n",
      "https://www.instagram.com/adityamadiraju/reel/DE_hPpAOhBj/\n",
      "\n",
      "https://www.instagram.com/adityamadiraju/reel/DE_QUEVuQJt/\n",
      "\n",
      "https://www.instagram.com/adityamadiraju/reel/DE-PUjoOIbd/\n",
      "\n",
      "https://www.instagram.com/adityamadiraju/reel/DE8mB8huVeA/\n",
      "\n",
      "https://www.instagram.com/adityamadiraju/reel/DE5N8k8u1XN/\n",
      "\n",
      "https://www.instagram.com/adityamadiraju/reel/DE48DyguUhf/\n",
      "\n",
      "https://www.instagram.com/adityamadiraju/reel/DE3jOYOOOXY/\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for id in posts[11:]:\n",
    "    print(f\"https://www.instagram.com{id}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 2/15 [00:06<00:43,  3.38s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[106], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m post \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(post\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m2\u001b[39m:])\n\u001b[1;32m      3\u001b[0m driver\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://www.instagram.com/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpost\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# try except block: a function to save the post like counts, posting date and append to csv file\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# and MAYBE download the post here\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for post in tqdm(posts[11:]):\n",
    "    post = '/'.join(post.split(\"/\")[2:])\n",
    "    driver.get(f\"https://www.instagram.com/{post}\")\n",
    "    time.sleep(3)\n",
    "    # try except block: a function to save the post like counts, posting date and append to csv file\n",
    "    # and MAYBE download the post here\n",
    "    try:\n",
    "        comments = get_all_comments()\n",
    "        save_comments(post.split(\"/\")[-2], comments)\n",
    "        time.sleep(2)\n",
    "        get_post_metadata(post.split(\"/\")[-2])\n",
    "    except:\n",
    "        continue\n",
    "    time.sleep(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [00:00<00:00, 1475.94it/s]\n",
      "100%|██████████| 38/38 [00:00<00:00, 2492.82it/s]\n",
      "100%|██████████| 43/43 [00:03<00:00, 12.58it/s]\n",
      "100%|██████████| 44/44 [00:00<00:00, 2667.98it/s]\n",
      "100%|██████████| 31/31 [00:00<00:00, 3024.64it/s]\n",
      " 93%|█████████▎| 41/44 [00:05<00:00,  7.52it/s]\n",
      " 28%|██▊       | 5/18 [00:08<00:23,  1.79s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[64], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m post\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m] \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m [i\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_comments.json\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39mlistdir(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcomments\u001b[39m\u001b[38;5;124m\"\u001b[39m)]:\n\u001b[1;32m      6\u001b[0m     driver\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://www.instagram.com/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpost\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 7\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;66;03m# try except block: a function to save the post like counts, posting date and append to csv file\u001b[39;00m\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;66;03m# and MAYBE download the post here\u001b[39;00m\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Step 4: get comments \n",
    "for profile in tqdm(profiles[7:]):\n",
    "    for post in tqdm(profile[\"posts\"]):\n",
    "        post = '/'.join(post.split(\"/\")[2:])\n",
    "        if post.split(\"/\")[-2] not in [i.replace(\"_comments.json\", \"\") for i in os.listdir(\"comments\")]:\n",
    "            driver.get(f\"https://www.instagram.com/{post}\")\n",
    "            time.sleep(3)\n",
    "            # try except block: a function to save the post like counts, posting date and append to csv file\n",
    "            # and MAYBE download the post here\n",
    "            try:\n",
    "                comments = get_all_comments()\n",
    "                save_comments(post.split(\"/\")[-2], comments)\n",
    "                time.sleep(2)\n",
    "                get_post_metadata(post.split(\"/\")[-2])\n",
    "            except:\n",
    "                continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'num_posts': '35',\n",
       " 'num_followers': '27.6K',\n",
       " 'num_following': '99',\n",
       " 'bio': 'shakhed Threads shakhedc Dancer 💃Professional Dancer  📲Tiktok 900k+ ~ shakhed 💌 ~ shakhedcollab@gmail.com  ',\n",
       " 'profile_picture': 'https://scontent-fra5-1.cdninstagram.com/v/t51.2885-19/480513890_9623714077688760_2363666855345936709_n.jpg?stp=dst-jpg_s150x150_tt6&_nc_ht=scontent-fra5-1.cdninstagram.com&_nc_cat=100&_nc_oc=Q6cZ2AF5VQdNGLg7SoIagAgPGmUS6Rxg0Chdfw8SpjqFQm14M3HOSvrWBp3hPrGc7t6LCac&_nc_ohc=peGBHnmFjbYQ7kNvgG-eZce&_nc_gid=9ae6e7576e134120b4e6cdffd08842bb&edm=AP4sbd4BAAAA&ccb=7-5&oh=00_AYGKP_g4dw5cSk8erYJ_L2ypEjrFlegHDd4zEUUQVkYbNg&oe=67D3D057&_nc_sid=7a9f4b',\n",
       " 'posts': ['/shakhedc/p/DEArjKAM5y3/',\n",
       "  '/shakhedc/p/DDxeWYJR4SJ/',\n",
       "  '/shakhedc/reel/DDtKqiiIw-C/',\n",
       "  '/shakhedc/p/DDSUTdTM3mQ/',\n",
       "  '/shakhedc/p/DCdWFYkoycl/',\n",
       "  '/shakhedc/reel/DB8ttVcsMgD/',\n",
       "  '/shakhedc/reel/DBbih8jsK3I/',\n",
       "  '/shakhedc/reel/DBMEdViMldA/',\n",
       "  '/shakhedc/p/DA6TIYYonMx/',\n",
       "  '/shakhedc/reel/DAnpJidMCBA/',\n",
       "  '/shakhedc/p/C-79KhVsMNS/',\n",
       "  '/shakhedc/p/C-2XmEjserI/',\n",
       "  '/shakhedc/p/C-I_XpXM5p7/',\n",
       "  '/shakhedc/p/C7RBwUVMStF/',\n",
       "  '/shakhedc/p/C7JJp5psmQl/',\n",
       "  '/shakhedc/reel/C4oDhsbLl8R/',\n",
       "  '/shakhedc/p/C4SszXTMR6z/',\n",
       "  '/shakhedc/reel/C36JYvdMJge/',\n",
       "  '/shakhedc/reel/C2mxa3gMZL0/',\n",
       "  '/shakhedc/reel/C2mxW_Ks8jV/',\n",
       "  '/shakhedc/p/C1hZYWnsoqZ/',\n",
       "  '/shakhedc/reel/C0fPBa5sBDa/',\n",
       "  '/shakhedc/reel/C0XdET6r9H_/',\n",
       "  '/shakhedc/reel/CzjiQo9LFBs/',\n",
       "  '/shakhedc/reel/CxdGaT_sSPs/',\n",
       "  '/shakhedc/p/Cm08lVVDBg4/',\n",
       "  '/shakhedc/reel/CmeXlS1pVKN/',\n",
       "  '/shakhedc/reel/CmeROMApsMU/',\n",
       "  '/shakhedc/p/CkRgp8lDPO_/',\n",
       "  '/shakhedc/p/ChShYmFDba4/',\n",
       "  '/shakhedc/reel/CZprC_ajBx-/',\n",
       "  '/shakhedc/reel/CXGf50cjxi9/']}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "profiles[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(os.listdir(\"comments\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reached the end of comments.\n",
      "Reached the end of comments.\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Comments saved to comments/DBNDq3YRW7S_comments.json\n"
     ]
    }
   ],
   "source": [
    "comments = get_all_comments()\n",
    "\n",
    "save_comments('DBNDq3YRW7S', comments)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>profile_thumbnail</th>\n",
       "      <th>comment</th>\n",
       "      <th>comment_image</th>\n",
       "      <th>likes</th>\n",
       "      <th>replies</th>\n",
       "      <th>time</th>\n",
       "      <th>comment_id</th>\n",
       "      <th>hidden</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>thecaydenbrown</td>\n",
       "      <td>https://scontent-fra3-2.cdninstagram.com/v/t51...</td>\n",
       "      <td>👏👏👏</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21 w</td>\n",
       "      <td>1fca1730744cefc26bcc5963e7db9d2f</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>idyllstyle</td>\n",
       "      <td>https://scontent-fra5-2.cdninstagram.com/v/t51...</td>\n",
       "      <td>🇺🇲🙏🏽😍💪🏽💯🥹</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21 w</td>\n",
       "      <td>c4dcfd946efead4cb9d4a9191fd24bf5</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cljnyc</td>\n",
       "      <td>https://scontent-fra5-1.cdninstagram.com/v/t51...</td>\n",
       "      <td>🗳️🗳️🗳️💙💙💙</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21 w</td>\n",
       "      <td>e5ad60d8efc42516ee12fce8cc3aa4c7</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>theunofbabies2020</td>\n",
       "      <td>https://scontent-fra5-2.cdninstagram.com/v/t51...</td>\n",
       "      <td>💙💙💙</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21 w</td>\n",
       "      <td>8ecd7a31c1beb92f347327e6862edf95</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bellforus</td>\n",
       "      <td>https://scontent-fra3-1.cdninstagram.com/v/t51...</td>\n",
       "      <td>I hope I get to vote for you one day!!!!</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21 w</td>\n",
       "      <td>9b3337b4dd88ae67ccd087ff7c298a03</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>katylied67</td>\n",
       "      <td>https://scontent-fra5-2.cdninstagram.com/v/t51...</td>\n",
       "      <td>THIS!!!!🙌❤️🙌🔥</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21 w</td>\n",
       "      <td>5c71a654ecea74acc1a0ff1212f33ed4</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>drtiffanysanders</td>\n",
       "      <td>https://scontent-fra5-2.cdninstagram.com/v/t51...</td>\n",
       "      <td>Good for you for getting the word out to remin...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21 w</td>\n",
       "      <td>ade17719a6dd340c75c537a2ce17de92</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>hotrod_5.0</td>\n",
       "      <td>https://scontent-fra3-1.cdninstagram.com/v/t51...</td>\n",
       "      <td>👏🏾👏🏾❤️👏🏾👏🏾</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20 w</td>\n",
       "      <td>0652c5f4be8c0c787a395cf913a1787e</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>perci.whitmore</td>\n",
       "      <td>https://scontent-fra5-1.cdninstagram.com/v/t51...</td>\n",
       "      <td>👏👏👏👏👏</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21 w</td>\n",
       "      <td>bde47b817e143bff8b6d797e2d9c5034</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>elianamarie777</td>\n",
       "      <td>https://scontent-fra3-2.cdninstagram.com/v/t51...</td>\n",
       "      <td>live laugh love mari 💗</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21 w</td>\n",
       "      <td>48371eb6107b9255f0560927a14b5d14</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>johnson_ven</td>\n",
       "      <td>https://scontent-fra3-1.cdninstagram.com/v/t51...</td>\n",
       "      <td>Thank you@littlemissflint!!!</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21 w</td>\n",
       "      <td>d92fa7bf2c704123d09129d5247c2218</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>niyastudios</td>\n",
       "      <td>https://scontent-fra3-1.cdninstagram.com/v/t51...</td>\n",
       "      <td>Indeed.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21 w</td>\n",
       "      <td>11be7978ae56666e47fb59dc7324c930</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>younggiftedgreen</td>\n",
       "      <td>https://scontent-fra5-1.cdninstagram.com/v/t51...</td>\n",
       "      <td>🔥🔥🔥🔥🔥</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21 w</td>\n",
       "      <td>8772e45fb6ede6b2b8ee7ac2e491a890</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>810__nie.gia_ta.nei__614</td>\n",
       "      <td>https://scontent-fra3-2.cdninstagram.com/v/t51...</td>\n",
       "      <td>Thanks@littlemissflintyou are God sent...keep ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21 w</td>\n",
       "      <td>452b40431eef384c79b47b75c6e06c4c</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>etyvina</td>\n",
       "      <td>https://scontent-fra3-2.cdninstagram.com/v/t51...</td>\n",
       "      <td>Reply</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20 w</td>\n",
       "      <td>94542a5d3ba0c7a6d1b19f2e380a85fe</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>youngblackandaware</td>\n",
       "      <td>https://scontent-fra3-1.cdninstagram.com/v/t51...</td>\n",
       "      <td>VOTE GREEN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>21 w</td>\n",
       "      <td>52b9fc6b98d4175c79dd6608a5b60a0e</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>cookie_thatone</td>\n",
       "      <td>https://scontent-fra3-1.cdninstagram.com/v/t51...</td>\n",
       "      <td>I voted early for us both. 💙💙💙</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21 w</td>\n",
       "      <td>b420e273ee50eaee827446b4a5d9ac95</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>prettieratnoon</td>\n",
       "      <td>https://scontent-fra5-2.cdninstagram.com/v/t51...</td>\n",
       "      <td>🔥🔥</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21 w</td>\n",
       "      <td>de61d88ec6306eee32601b625bdc102e</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>pistongreg</td>\n",
       "      <td>https://scontent-fra5-1.cdninstagram.com/v/t51...</td>\n",
       "      <td>From one Flintstone to another Voted blue in N...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21 w</td>\n",
       "      <td>0b8872e90b384f897a00d291af986a1a</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>oliver_jun_t</td>\n",
       "      <td>https://scontent-fra5-2.cdninstagram.com/v/t51...</td>\n",
       "      <td>Reply</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21 w</td>\n",
       "      <td>be4a58ce111fd9e80c6d796133529140</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>cookie_thatone</td>\n",
       "      <td>https://scontent-fra3-1.cdninstagram.com/v/t51...</td>\n",
       "      <td>😍😍😍🥰</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21 w</td>\n",
       "      <td>7c2e643f221ef4f0d97d1188ad654750</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>beatricemulaney</td>\n",
       "      <td>https://scontent-fra3-1.cdninstagram.com/v/t51...</td>\n",
       "      <td>Sis, I canNOT wait until you can vote, and I c...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21 w</td>\n",
       "      <td>cbe3026150c683419326cd5c8d9f78c9</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>ogima_tjehk</td>\n",
       "      <td>https://scontent-fra3-2.cdninstagram.com/v/t51...</td>\n",
       "      <td>A fiduciary duty is the legal responsibility t...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21 w</td>\n",
       "      <td>f1572a32af794604d319a62b0de9fac9</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>itsjustsmitty22</td>\n",
       "      <td>https://scontent-fra3-1.cdninstagram.com/v/t51...</td>\n",
       "      <td>Do it clap</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>21 w</td>\n",
       "      <td>38e3ecca0fda677bf145431891be3426</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>americasmiraclefoundation</td>\n",
       "      <td>https://scontent-fra3-2.cdninstagram.com/v/t51...</td>\n",
       "      <td>🔥</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21 w</td>\n",
       "      <td>901c0488e86fd7d1aa4ee6714fc9fdd2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>donnaburks8</td>\n",
       "      <td>https://scontent-fra3-1.cdninstagram.com/v/t51...</td>\n",
       "      <td>Man, You ain’t doing nothing nothing but getti...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21 w</td>\n",
       "      <td>14721ec2935743633d0fab30df616f61</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>ogima_tjehk</td>\n",
       "      <td>https://scontent-fra3-2.cdninstagram.com/v/t51...</td>\n",
       "      <td>WE are the Sovereign Creditorsen aFiduciary Re...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21 w</td>\n",
       "      <td>122f474ee8341f7d24a835402c96cf10</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     username  \\\n",
       "0              thecaydenbrown   \n",
       "1                  idyllstyle   \n",
       "2                      cljnyc   \n",
       "3           theunofbabies2020   \n",
       "4                   bellforus   \n",
       "5                  katylied67   \n",
       "6            drtiffanysanders   \n",
       "7                  hotrod_5.0   \n",
       "8              perci.whitmore   \n",
       "9              elianamarie777   \n",
       "10                johnson_ven   \n",
       "11                niyastudios   \n",
       "12           younggiftedgreen   \n",
       "13   810__nie.gia_ta.nei__614   \n",
       "14                    etyvina   \n",
       "15         youngblackandaware   \n",
       "16             cookie_thatone   \n",
       "17             prettieratnoon   \n",
       "18                 pistongreg   \n",
       "19               oliver_jun_t   \n",
       "20             cookie_thatone   \n",
       "21            beatricemulaney   \n",
       "22                ogima_tjehk   \n",
       "23            itsjustsmitty22   \n",
       "24  americasmiraclefoundation   \n",
       "25                donnaburks8   \n",
       "26                ogima_tjehk   \n",
       "\n",
       "                                    profile_thumbnail  \\\n",
       "0   https://scontent-fra3-2.cdninstagram.com/v/t51...   \n",
       "1   https://scontent-fra5-2.cdninstagram.com/v/t51...   \n",
       "2   https://scontent-fra5-1.cdninstagram.com/v/t51...   \n",
       "3   https://scontent-fra5-2.cdninstagram.com/v/t51...   \n",
       "4   https://scontent-fra3-1.cdninstagram.com/v/t51...   \n",
       "5   https://scontent-fra5-2.cdninstagram.com/v/t51...   \n",
       "6   https://scontent-fra5-2.cdninstagram.com/v/t51...   \n",
       "7   https://scontent-fra3-1.cdninstagram.com/v/t51...   \n",
       "8   https://scontent-fra5-1.cdninstagram.com/v/t51...   \n",
       "9   https://scontent-fra3-2.cdninstagram.com/v/t51...   \n",
       "10  https://scontent-fra3-1.cdninstagram.com/v/t51...   \n",
       "11  https://scontent-fra3-1.cdninstagram.com/v/t51...   \n",
       "12  https://scontent-fra5-1.cdninstagram.com/v/t51...   \n",
       "13  https://scontent-fra3-2.cdninstagram.com/v/t51...   \n",
       "14  https://scontent-fra3-2.cdninstagram.com/v/t51...   \n",
       "15  https://scontent-fra3-1.cdninstagram.com/v/t51...   \n",
       "16  https://scontent-fra3-1.cdninstagram.com/v/t51...   \n",
       "17  https://scontent-fra5-2.cdninstagram.com/v/t51...   \n",
       "18  https://scontent-fra5-1.cdninstagram.com/v/t51...   \n",
       "19  https://scontent-fra5-2.cdninstagram.com/v/t51...   \n",
       "20  https://scontent-fra3-1.cdninstagram.com/v/t51...   \n",
       "21  https://scontent-fra3-1.cdninstagram.com/v/t51...   \n",
       "22  https://scontent-fra3-2.cdninstagram.com/v/t51...   \n",
       "23  https://scontent-fra3-1.cdninstagram.com/v/t51...   \n",
       "24  https://scontent-fra3-2.cdninstagram.com/v/t51...   \n",
       "25  https://scontent-fra3-1.cdninstagram.com/v/t51...   \n",
       "26  https://scontent-fra3-2.cdninstagram.com/v/t51...   \n",
       "\n",
       "                                              comment  comment_image  likes  \\\n",
       "0                                                 👏👏👏            NaN    NaN   \n",
       "1                                           🇺🇲🙏🏽😍💪🏽💯🥹            NaN    NaN   \n",
       "2                                           🗳️🗳️🗳️💙💙💙            NaN    NaN   \n",
       "3                                                 💙💙💙            NaN    NaN   \n",
       "4            I hope I get to vote for you one day!!!!            NaN    2.0   \n",
       "5                                       THIS!!!!🙌❤️🙌🔥            NaN    NaN   \n",
       "6   Good for you for getting the word out to remin...            NaN    7.0   \n",
       "7                                          👏🏾👏🏾❤️👏🏾👏🏾            NaN    NaN   \n",
       "8                                               👏👏👏👏👏            NaN    NaN   \n",
       "9                              live laugh love mari 💗            NaN    NaN   \n",
       "10                       Thank you@littlemissflint!!!            NaN    NaN   \n",
       "11                                            Indeed.            NaN    NaN   \n",
       "12                                              🔥🔥🔥🔥🔥            NaN    NaN   \n",
       "13  Thanks@littlemissflintyou are God sent...keep ...            NaN    NaN   \n",
       "14                                              Reply            NaN    NaN   \n",
       "15                                         VOTE GREEN            NaN    2.0   \n",
       "16                     I voted early for us both. 💙💙💙            NaN    4.0   \n",
       "17                                                 🔥🔥            NaN    NaN   \n",
       "18  From one Flintstone to another Voted blue in N...            NaN    NaN   \n",
       "19                                              Reply            NaN    NaN   \n",
       "20                                               😍😍😍🥰            NaN    NaN   \n",
       "21  Sis, I canNOT wait until you can vote, and I c...            NaN    4.0   \n",
       "22  A fiduciary duty is the legal responsibility t...            NaN    NaN   \n",
       "23                                         Do it clap            NaN    NaN   \n",
       "24                                                  🔥            NaN    NaN   \n",
       "25  Man, You ain’t doing nothing nothing but getti...            NaN    NaN   \n",
       "26  WE are the Sovereign Creditorsen aFiduciary Re...            NaN    NaN   \n",
       "\n",
       "    replies  time                        comment_id  hidden  \n",
       "0       NaN  21 w  1fca1730744cefc26bcc5963e7db9d2f   False  \n",
       "1       NaN  21 w  c4dcfd946efead4cb9d4a9191fd24bf5   False  \n",
       "2       NaN  21 w  e5ad60d8efc42516ee12fce8cc3aa4c7   False  \n",
       "3       NaN  21 w  8ecd7a31c1beb92f347327e6862edf95   False  \n",
       "4       NaN  21 w  9b3337b4dd88ae67ccd087ff7c298a03   False  \n",
       "5       NaN  21 w  5c71a654ecea74acc1a0ff1212f33ed4   False  \n",
       "6       NaN  21 w  ade17719a6dd340c75c537a2ce17de92   False  \n",
       "7       NaN  20 w  0652c5f4be8c0c787a395cf913a1787e   False  \n",
       "8       NaN  21 w  bde47b817e143bff8b6d797e2d9c5034   False  \n",
       "9       NaN  21 w  48371eb6107b9255f0560927a14b5d14   False  \n",
       "10      NaN  21 w  d92fa7bf2c704123d09129d5247c2218   False  \n",
       "11      NaN  21 w  11be7978ae56666e47fb59dc7324c930   False  \n",
       "12      NaN  21 w  8772e45fb6ede6b2b8ee7ac2e491a890   False  \n",
       "13      NaN  21 w  452b40431eef384c79b47b75c6e06c4c   False  \n",
       "14      NaN  20 w  94542a5d3ba0c7a6d1b19f2e380a85fe   False  \n",
       "15      7.0  21 w  52b9fc6b98d4175c79dd6608a5b60a0e   False  \n",
       "16      NaN  21 w  b420e273ee50eaee827446b4a5d9ac95   False  \n",
       "17      NaN  21 w  de61d88ec6306eee32601b625bdc102e   False  \n",
       "18      NaN  21 w  0b8872e90b384f897a00d291af986a1a   False  \n",
       "19      NaN  21 w  be4a58ce111fd9e80c6d796133529140   False  \n",
       "20      NaN  21 w  7c2e643f221ef4f0d97d1188ad654750   False  \n",
       "21      NaN  21 w  cbe3026150c683419326cd5c8d9f78c9   False  \n",
       "22      NaN  21 w  f1572a32af794604d319a62b0de9fac9   False  \n",
       "23      3.0  21 w  38e3ecca0fda677bf145431891be3426   False  \n",
       "24      NaN  21 w  901c0488e86fd7d1aa4ee6714fc9fdd2   False  \n",
       "25      NaN  21 w  14721ec2935743633d0fab30df616f61    True  \n",
       "26      NaN  21 w  122f474ee8341f7d24a835402c96cf10    True  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_json(\"comments/DBNDq3YRW7S_comments.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing DFAlpCeuytZ.html...\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Saved 1529 comments to comments/DFAlpCeuytZ_comments.json\n",
      "Processing DFIoZPduidP.html...\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Saved 273 comments to comments/DFIoZPduidP_comments.json\n",
      "Processing DE48DyguUhf.html...\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Saved 156 comments to comments/DE48DyguUhf_comments.json\n",
      "Processing DFLM-6KOs3u.html...\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Saved 897 comments to comments/DFLM-6KOs3u_comments.json\n",
      "Processing DE3jOYOOOXY.html...\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Saved 639 comments to comments/DE3jOYOOOXY_comments.json\n",
      "Processing DFHR1YeONaG.html...\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Saved 2019 comments to comments/DFHR1YeONaG_comments.json\n",
      "Processing DE8mB8huVeA.html...\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Saved 330 comments to comments/DE8mB8huVeA_comments.json\n",
      "Processing DFGJGwgOaE-.html...\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Saved 219 comments to comments/DFGJGwgOaE-_comments.json\n",
      "Processing DE-PUjoOIbd.html...\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Saved 282 comments to comments/DE-PUjoOIbd_comments.json\n",
      "Processing DFIg09Lu91i.html...\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Saved 141 comments to comments/DFIg09Lu91i_comments.json\n",
      "Processing DE_hPpAOhBj.html...\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Saved 2157 comments to comments/DE_hPpAOhBj_comments.json\n",
      "Processing DFLpKTPv1L-.html...\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Saved 635 comments to comments/DFLpKTPv1L-_comments.json\n",
      "Processing DFK094auhht.html...\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Saved 798 comments to comments/DFK094auhht_comments.json\n",
      "Processing DE5N8k8u1XN.html...\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Saved 312 comments to comments/DE5N8k8u1XN_comments.json\n",
      "Processing DE_QUEVuQJt.html...\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Error extracting comment: 'in <string>' requires string as left operand, not NoneType\n",
      "Saved 1653 comments to comments/DE_QUEVuQJt_comments.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import hashlib\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Directory containing the HTML files\n",
    "HTML_DIR = \"pages\"  # Change this to the actual directory where your files are stored\n",
    "OUTPUT_DIR = \"comments\"   # Change this if needed\n",
    "\n",
    "# Ensure the output directory exists\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "def extract_comment(comment, hidden=False):\n",
    "    \"\"\"Extracts relevant comment information from the parsed HTML.\"\"\"\n",
    "    try:\n",
    "        # 1. Extract Username\n",
    "        username_tag = comment.find(\"a\", href=True)\n",
    "        username = username_tag['href'].strip().replace(\"/\", \"\") if username_tag else None\n",
    "\n",
    "        # 2. Extract Profile Thumbnail\n",
    "        profile_img_tag = username_tag.find(\"img\") if username_tag else None\n",
    "        profile_thumbnail = profile_img_tag[\"src\"] if profile_img_tag else None\n",
    "\n",
    "        # 3. Extract Comment Text\n",
    "        comment_text = None\n",
    "        all_spans = comment.find_all(\"span\", dir=\"auto\")  # Extract spans with actual text\n",
    "        for span in all_spans:\n",
    "            span_text = span.get_text(strip=True)\n",
    "            if span_text and username not in span_text and not span_text.endswith((\"w\", \"d\", \"h\", \"m\", \"s\")):\n",
    "                comment_text = span_text  # Ignore timestamps\n",
    "                break  # Take only the first valid comment text\n",
    "\n",
    "        # 4. Extract Comment Image (if any)\n",
    "        comment_image = None\n",
    "        for img_tag in comment.find_all(\"img\"):\n",
    "            img_src = img_tag[\"src\"]\n",
    "            if profile_thumbnail and img_src != profile_thumbnail:\n",
    "                comment_image = img_src\n",
    "                break  # Take only the first relevant image\n",
    "\n",
    "        # 5. Extract Likes\n",
    "        num_likes = None\n",
    "        for span in all_spans:\n",
    "            text = span.get_text(separator=' ')\n",
    "            if text.endswith('likes'):\n",
    "                try:\n",
    "                    num_likes = int(text.split(\" \")[0])  # Extract number before 'likes'\n",
    "                except ValueError:\n",
    "                    num_likes = None\n",
    "\n",
    "        # 6. Extract Replies Count\n",
    "        num_replies = None\n",
    "        for span in all_spans:\n",
    "            text = span.get_text(strip=True)\n",
    "            if \"replies\" in text and \"View all\" in text:\n",
    "                match = re.search(r\"View all (\\d+) replies\", text)\n",
    "                if match:\n",
    "                    num_replies = int(match.group(1))\n",
    "            elif text.startswith(\"View \") and text.endswith(\" replies\"):\n",
    "                match = re.search(r\"View (\\d+) replies\", text)\n",
    "                if match:\n",
    "                    num_replies = int(match.group(1))\n",
    "\n",
    "        # 7. Extract Timestamp\n",
    "        time_tag = comment.find(\"time\")\n",
    "        commented_time = time_tag.text.strip() if time_tag else None\n",
    "\n",
    "        # 8. Generate Unique Comment ID\n",
    "        comment_id_source = f\"{username}-{commented_time}-{comment_text}\"\n",
    "        comment_id = hashlib.md5(comment_id_source.encode()).hexdigest() if comment_text else None\n",
    "\n",
    "        return {\n",
    "            \"username\": username,\n",
    "            \"profile_thumbnail\": profile_thumbnail,\n",
    "            \"comment\": comment_text,\n",
    "            \"comment_image\": comment_image,\n",
    "            \"likes\": num_likes,\n",
    "            \"replies\": num_replies,\n",
    "            \"time\": commented_time,\n",
    "            \"comment_id\": comment_id,\n",
    "            \"hidden\": hidden\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting comment: {e}\")\n",
    "        return None\n",
    "\n",
    "def process_html_file(file_path, post_id):\n",
    "    \"\"\"Parses an HTML file and extracts comments.\"\"\"\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        soup = BeautifulSoup(file, \"html.parser\")\n",
    "\n",
    "    all_comments = []\n",
    "    found_hidden_div = False\n",
    "\n",
    "    # Find all comment divs\n",
    "    comment_divs = soup.find_all(\"div\", class_=\"\")  # Adjust this if needed for correct class\n",
    "\n",
    "    for comment in comment_divs:\n",
    "        comment_text = comment.text.strip()\n",
    "\n",
    "        # Detect \"Hidden by Instagram\" marker\n",
    "        if \"Hidden by Instagram\" in comment_text:\n",
    "            found_hidden_div = True\n",
    "            continue  # Skip the marker itself\n",
    "\n",
    "        # Extract comment details\n",
    "        extracted_comment = extract_comment(comment, hidden=found_hidden_div)\n",
    "        if extracted_comment:\n",
    "            all_comments.append(extracted_comment)\n",
    "\n",
    "    return all_comments\n",
    "\n",
    "def save_comments(post_id, comments):\n",
    "    \"\"\"Saves extracted comments to a JSON file.\"\"\"\n",
    "    output_path = os.path.join(OUTPUT_DIR, f\"{post_id}_comments.json\")\n",
    "    with open(output_path, 'w', encoding='utf-8') as file:\n",
    "        json.dump(comments, file, indent=4, ensure_ascii=False)\n",
    "    print(f\"Saved {len(comments)} comments to {output_path}\")\n",
    "\n",
    "def get_post_metadata(postId, html):\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    for i in soup.find_all(\"a\"):\n",
    "        if \"liked_by\" in i['href']:\n",
    "            likes = i.getText().replace(\" likes\", \"\").replace(\",\", \"\")\n",
    "            break\n",
    "    postTime = soup.find(\"time\")['datetime']\n",
    "    with open('post_metadata.csv', 'a') as f:\n",
    "        f.writelines(f\"{postId},{likes},{postTime}\\n\")\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main function to process all HTML files.\"\"\"\n",
    "    for filename in os.listdir(HTML_DIR):\n",
    "        if filename.endswith(\".html\"):\n",
    "            post_id = os.path.splitext(filename)[0]  # Extract post ID from filename\n",
    "            file_path = os.path.join(HTML_DIR, filename)\n",
    "            print(f\"Processing {filename}...\")\n",
    "\n",
    "            comments = process_html_file(file_path, post_id)\n",
    "            save_comments(post_id, comments)\n",
    "            get_post_metadata(post_id, open(file_path).read())\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
